I dedicated myself to developing a Desktop application focused on weather forecasting, integrating various technologies to create a complete solution: an ETL pipeline that performs data extraction via API, transformation distributed between SQL and Python, and final loading into automatically organized CSV files.

ğŸŸ¢ What does the app do?  
1ï¸âƒ£ Allows the user to select the city to be analyzed through a graphical interface.
2ï¸âƒ£ Consumes meteorological data in JSON format from WeatherAPI.
3ï¸âƒ£ Stores the data in a MySQL database created and configured automatically.
4ï¸âƒ£ Processes information with SQL queries, generating structured datasets for analysis.
5ï¸âƒ£ Returns the processed data to Python for vector operations with NumPy and final adjustments.
6ï¸âƒ£ Generates charts with Matplotlib to visualize meteorological information.
7ï¸âƒ£ Displays results in dashboards (CustomTkinter), with 4 tabs:
ğŸŒ¡ï¸ Temperature
ğŸ’§ Humidity
ğŸŒ§ï¸ Precipitation (rain/snow)
ğŸ“Š General Panel with current data and projections
8ï¸âƒ£ Includes a button that automatically exports the data to CSV files, creating an organized directory hierarchy, enabling further analysis in Excel, Power BI, and other tools.

ğŸ“– Technologies and concepts applied:

â–ªï¸NumPy â€“ vector operations

â–ªï¸Pandas â€“ data cleaning and export

â–ªï¸MySQL + mysql-connector-python â€“ structured storage and processing

â–ªï¸Requests â€“ API consumption

â–ªï¸OS â€“ directory and file automation

â–ªï¸Matplotlib â€“ data visualization

â–ªï¸CustomTkinter â€“ interactive graphical interface

â–ªï¸SQL â€“ queries and modeling

â–ªï¸OOP â€“ code organization and reuse

â–ªï¸Advanced Python â€“ use of decorators and custom exceptions

Complete ETL pipeline: API JSON â†’ SQL â†’ NumPy â†’ GUI/Pandas â†’ CSV

Modularization â€“ separation of code into packages and modules, facilitating maintenance and scalability
